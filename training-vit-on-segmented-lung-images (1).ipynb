{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":2332307,"sourceType":"datasetVersion","datasetId":891819},{"sourceId":4962811,"sourceType":"datasetVersion","datasetId":2878166},{"sourceId":280400,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":240230,"modelId":261877},{"sourceId":346130,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":289191,"modelId":309929}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport cv2\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow.keras.models import load_model\nfrom timm import create_model\nimport torch\nfrom torch import nn, optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms\nfrom sklearn.metrics import accuracy_score, classification_report\nfrom tqdm import tqdm\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-29T19:37:49.898674Z","iopub.execute_input":"2025-05-29T19:37:49.898916Z","iopub.status.idle":"2025-05-29T19:38:14.316361Z","shell.execute_reply.started":"2025-05-29T19:37:49.898897Z","shell.execute_reply":"2025-05-29T19:38:14.315373Z"}},"outputs":[{"name":"stderr","text":"2025-05-29 19:37:51.867361: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1748547472.052812      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1748547472.110066      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"def jaccard_index(y_true, y_pred, smooth=100):\n    y_true_f = tf.reshape(tf.cast(y_true, tf.float32), [-1])\n    y_pred_f = tf.reshape(tf.cast(y_pred, tf.float32), [-1])\n    intersection = tf.reduce_sum(y_true_f * y_pred_f)\n    total = tf.reduce_sum(y_true_f) + tf.reduce_sum(y_pred_f) - intersection\n    return (intersection + smooth) / (total + smooth)\n\ndef dice_coefficient(y_true, y_pred, smooth=1):\n    y_true_f = tf.reshape(tf.cast(y_true, tf.float32), [-1])\n    y_pred_f = tf.reshape(tf.cast(y_pred, tf.float32), [-1])\n    intersection = tf.reduce_sum(y_true_f * y_pred_f)\n    return (2. * intersection + smooth) / (tf.reduce_sum(y_true_f) + tf.reduce_sum(y_pred_f) + smooth)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-29T19:38:23.209609Z","iopub.execute_input":"2025-05-29T19:38:23.210413Z","iopub.status.idle":"2025-05-29T19:38:23.215774Z","shell.execute_reply.started":"2025-05-29T19:38:23.210391Z","shell.execute_reply":"2025-05-29T19:38:23.215023Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"segment_model = load_model(\n    '/kaggle/input/segment_model/keras/default/1/best_model (1).keras',\n    custom_objects={'dice_coefficient': dice_coefficient, 'jaccard_index': jaccard_index}\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-29T19:38:27.369291Z","iopub.execute_input":"2025-05-29T19:38:27.369851Z","iopub.status.idle":"2025-05-29T19:38:30.752916Z","shell.execute_reply.started":"2025-05-29T19:38:27.369825Z","shell.execute_reply":"2025-05-29T19:38:30.752362Z"}},"outputs":[{"name":"stderr","text":"I0000 00:00:1748547507.778369      35 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\nI0000 00:00:1748547507.779052      35 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13942 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import os\nimport pandas as pd\nimport numpy as np\nfrom PIL import Image\nimport torch\nfrom torch.utils.data import Dataset\nimport cv2  # for resizing\n\nclass SegmentedChestXrayDataset(Dataset):\n    def __init__(self, csv_path, image_folder, segment_model, transform=None, limit_normal=None):\n        self.df = pd.read_csv(csv_path)\n        self.image_folder = image_folder\n        self.segment_model = segment_model\n        self.transform = transform\n        self.data = []\n\n        normal_count = 0\n        for _, row in self.df.iterrows():\n            label = 1 if row['image_type'].strip().lower() == 'tb' else 0\n            if label == 0 and limit_normal is not None:\n                if normal_count >= limit_normal:\n                    continue\n                normal_count += 1\n            self.data.append((row['fname'], label))\n\n    def __len__(self):\n        return len(self.data)\n\n    def __getitem__(self, idx):\n        img_name, label = self.data[idx]\n        img_path = os.path.join(self.image_folder, img_name)\n\n        # Load image\n        image = Image.open(img_path).convert(\"RGB\")\n        image_np = np.array(image)\n        original_shape = image_np.shape[:2]  # (H, W)\n\n        # Resize for segmentation model\n        resized_input = cv2.resize(image_np, (256, 256)).astype(np.float32) / 255.0\n        resized_input = np.expand_dims(resized_input, axis=0)  # shape (1, 256, 256, 3)\n\n        # Predict mask\n        mask = self.segment_model.predict(resized_input)[0]\n        if mask.ndim == 3:\n            mask = mask[:, :, 0]  # (256, 256)\n\n        # Resize mask back to original image size and binarize\n        mask_resized = cv2.resize(mask, (original_shape[1], original_shape[0]))\n        mask_binary = (mask_resized > 0.5).astype(np.uint8)\n\n        # Apply mask to image\n        masked_image = image_np * np.expand_dims(mask_binary, axis=-1)\n\n        # Convert to PIL image for transforms\n        masked_pil = Image.fromarray(masked_image.astype(np.uint8))\n\n        if self.transform:\n            masked_pil = self.transform(masked_pil)\n\n        return masked_pil, label\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-29T19:38:35.129754Z","iopub.execute_input":"2025-05-29T19:38:35.130477Z","iopub.status.idle":"2025-05-29T19:38:35.139187Z","shell.execute_reply.started":"2025-05-29T19:38:35.130451Z","shell.execute_reply":"2025-05-29T19:38:35.138453Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"import os\nimport torchvision.transforms as transforms\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nroot_dir = '/kaggle/input/tbx11k-simplified/tbx11k-simplified'\n\ntransform_vit = transforms.Compose([\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomRotation(10),\n    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n    transforms.Resize((224, 224)),\n    transforms.ToTensor()\n])\n\n# Define paths\ncsv_path = os.path.join(root_dir, \"data.csv\")\nimage_folder = os.path.join(root_dir, \"images\")\n\n# Create dataset\ndataset = SegmentedChestXrayDataset(\n    csv_path=csv_path,\n    image_folder=image_folder,\n    segment_model=segment_model,  # make sure this model is already loaded\n    transform=transform_vit,\n    limit_normal=1000\n)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-29T19:38:39.209782Z","iopub.execute_input":"2025-05-29T19:38:39.210459Z","iopub.status.idle":"2025-05-29T19:38:39.573024Z","shell.execute_reply.started":"2025-05-29T19:38:39.210433Z","shell.execute_reply":"2025-05-29T19:38:39.572431Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"train_size = int(0.8 * len(dataset))\ntest_size = len(dataset) - train_size\ntrain_set, test_set = torch.utils.data.random_split(dataset, [train_size, test_size])\n\ntrain_loader = DataLoader(train_set, batch_size=16, shuffle=True)\ntest_loader = DataLoader(test_set, batch_size=16, shuffle=False)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-29T19:38:43.249624Z","iopub.execute_input":"2025-05-29T19:38:43.249939Z","iopub.status.idle":"2025-05-29T19:38:43.256644Z","shell.execute_reply.started":"2025-05-29T19:38:43.249920Z","shell.execute_reply":"2025-05-29T19:38:43.255916Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"vit_model = create_model('vit_base_patch16_224', pretrained=True, num_classes=2)\nvit_model.to(device)\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(vit_model.parameters(), lr=1e-4)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-05T19:47:21.957156Z","iopub.execute_input":"2025-06-05T19:47:21.957417Z","iopub.status.idle":"2025-06-05T19:47:21.965499Z","shell.execute_reply.started":"2025-06-05T19:47:21.957398Z","shell.execute_reply":"2025-06-05T19:47:21.964618Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_35/2071173039.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mvit_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'vit_base_patch16_224'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpretrained\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mvit_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvit_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'create_model' is not defined"],"ename":"NameError","evalue":"name 'create_model' is not defined","output_type":"error"}],"execution_count":4},{"cell_type":"code","source":"output = vit_model(input_tensor)\nprint(output.shape)  # Should be [1, num_classes], e.g., [1, 2]\nprint(output)        # Check if logits look reasonable (not all zeros)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-05T19:47:08.591708Z","iopub.execute_input":"2025-06-05T19:47:08.591967Z","iopub.status.idle":"2025-06-05T19:47:08.599646Z","shell.execute_reply.started":"2025-06-05T19:47:08.591947Z","shell.execute_reply":"2025-06-05T19:47:08.598762Z"}},"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_35/190242411.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvit_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Should be [1, num_classes], e.g., [1, 2]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m        \u001b[0;31m# Check if logits look reasonable (not all zeros)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'vit_model' is not defined"],"ename":"NameError","evalue":"name 'vit_model' is not defined","output_type":"error"}],"execution_count":2},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\nimport matplotlib.pyplot as plt\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-29T19:38:53.929293Z","iopub.execute_input":"2025-05-29T19:38:53.929561Z","iopub.status.idle":"2025-05-29T19:38:53.933396Z","shell.execute_reply.started":"2025-05-29T19:38:53.929542Z","shell.execute_reply":"2025-05-29T19:38:53.932678Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"num_epochs = 100\n\ntrain_losses = []\nval_accuracies = []\nval_recalls = []\nval_precisions = []\nval_f1s = []\n\nfor epoch in range(num_epochs):\n    vit_model.train()\n    total_loss = 0\n\n    for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\"):\n        images, labels = images.to(device), labels.to(device)\n        optimizer.zero_grad()\n        outputs = vit_model(images)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        total_loss += loss.item()\n\n    avg_loss = total_loss / len(train_loader)\n    train_losses.append(avg_loss)\n\n    # --- Validation ---\n    vit_model.eval()\n    y_true_val, y_pred_val = [], []\n    val_loss = 0\n\n    with torch.no_grad():\n        for images, labels in test_loader:\n            images, labels = images.to(device), labels.to(device)\n            outputs = vit_model(images)\n            loss = criterion(outputs, labels)\n            val_loss += loss.item()\n            preds = torch.argmax(outputs, dim=1).cpu().numpy()\n            y_pred_val.extend(preds)\n            y_true_val.extend(labels.cpu().numpy())\n\n    val_acc = accuracy_score(y_true_val, y_pred_val)\n    precision = precision_score(y_true_val, y_pred_val, average='binary')\n    recall = recall_score(y_true_val, y_pred_val, average='binary')  # sensitivity\n    f1 = f1_score(y_true_val, y_pred_val, average='binary')\n\n    val_accuracies.append(val_acc)\n    val_precisions.append(precision)\n    val_recalls.append(recall)\n    val_f1s.append(f1)\n\n    print(f\"Epoch {epoch+1}/{num_epochs} - \"\n          f\"Train Loss: {avg_loss:.4f} - \"\n          f\"Val Acc: {val_acc:.4f} - \"\n          f\"Precision: {precision:.4f} - \"\n          f\"Recall (Sensitivity): {recall:.4f} - \"\n          f\"F1 Score: {f1:.4f}\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"epochs = range(1, num_epochs+1)\n\nplt.figure(figsize=(16, 10))\n\nplt.subplot(2, 2, 1)\nplt.plot(epochs, train_losses, label='Train Loss')\nplt.title('Loss vs Epoch')\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.grid(True)\nplt.legend()\n\nplt.subplot(2, 2, 2)\nplt.plot(epochs, val_accuracies, label='Val Accuracy', color='green')\nplt.title('Accuracy vs Epoch')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.grid(True)\nplt.legend()\n\nplt.subplot(2, 2, 3)\nplt.plot(epochs, val_recalls, label='Recall (Sensitivity)', color='red')\nplt.title('Sensitivity (Recall) vs Epoch')\nplt.xlabel('Epoch')\nplt.ylabel('Recall')\nplt.grid(True)\nplt.legend()\n\nplt.subplot(2, 2, 4)\nplt.plot(epochs, val_precisions, label='Precision', color='purple')\nplt.plot(epochs, val_f1s, label='F1 Score', color='orange')\nplt.title('Precision & F1 Score vs Epoch')\nplt.xlabel('Epoch')\nplt.ylabel('Score')\nplt.grid(True)\nplt.legend()\n\nplt.tight_layout()\nplt.show()\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"torch.save(vit_model.state_dict(), 'vit_model.pth')\nprint(\"Model saved to vit_model.pth\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-05-29T19:42:21.809608Z","iopub.execute_input":"2025-05-29T19:42:21.810185Z","iopub.status.idle":"2025-05-29T19:42:22.234263Z","shell.execute_reply.started":"2025-05-29T19:42:21.810161Z","shell.execute_reply":"2025-05-29T19:42:22.233470Z"}},"outputs":[{"name":"stdout","text":"Model saved to vit_model.pth\n","output_type":"stream"}],"execution_count":10}]}